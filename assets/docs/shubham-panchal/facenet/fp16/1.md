
# Lite shubham-panchal/facenet/fp16/1

A TensorFlow Lite build for the FaceNet model which 
would help you generate a unique 
128-dimensional embedding ( vector ) for given face image.

<!-- asset-path: https://github.com/shubham0204/TensorFlowHub_Models/blob/master/facenet/facenet_fp16_v1/1.tflite?raw=true -->
<!-- parent-model: shubham-panchal/facenet/1 -->

### Overview

The FaceNet model is used to generate to a unique embedding 
for a given image of a user. These embeddings could be compared 
with each other using metrics like cosine similarity or L2 norm and has 
been used in various face recognition systems.

* The model is trained on 
[MS-Celeb-1M dataset](https://www.microsoft.com/en-us/research/publication/ms-celeb-1m-dataset-benchmark-large-scale-face-recognition-2/).

* The model takes a RGB image of shape `[1,160,160,3]` 
i.e 160 * 160  image and outputs a 128 dimensional embedding 
of shape `[1,128]`.

* The TFLite model is `float16` quantized. The quantization is performed 
following this [guide](https://www.tensorflow.org/lite/performance/post_training_float16_quant).

* The TFLite model has been populated with metadata to help you 
with the input/output shapes as well as data types.

### Example Usage

To learn how to use the FaceNet TFLite model in an Android app, 
follow this story : 
[Using FaceNet For On-Device Face Recognition With Android](https://towardsdatascience.com/using-facenet-for-on-device-face-recognition-with-android-f84e36e19761)

You may fork/clone the [GitHub repo](https://github.com/shubham0204/FaceRecognition_With_FaceNet_Android) too.

### Acknowledgements

Thanks to Hiroki Taniai ( GitHub : https://github.com/nyoki-mtl ) for providing the 
pretrained FaceNet model as a Keras model ( `.h5` ) in this [repo](https://github.com/nyoki-mtl/keras-facenet).

